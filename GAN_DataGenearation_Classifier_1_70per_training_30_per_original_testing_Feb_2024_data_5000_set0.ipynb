{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C71ntYux94gE"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import pandas as pd\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EJOdC3y_LM5"
      },
      "source": [],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a93dtQn5-BQj",
        "outputId": "ec6231d8-7c52-47f5-8f38-b647c9d0e8da"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NZ2qGdL-DkB"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('drive/My Drive/churn-5000.csv')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXeWn2tZ-EWx"
      },
      "source": [
        "num_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
        "cat_df = df.select_dtypes(include=['object']).copy()\n",
        "\n",
        "# Categorical boolean mask\n",
        "categorical_feature_mask = cat_df.dtypes==object\n",
        "# filter categorical columns using mask and turn it into a list\n",
        "categorical_cols = cat_df.columns[categorical_feature_mask].tolist()\n",
        "\n",
        "import numpy as np\n",
        "#conData=np.log(0.00001 + 1)\n",
        "conData=0\n",
        "cat_df=cat_df.fillna(conData)\n",
        "num_df=num_df.fillna(conData)\n",
        "cat_df=cat_df.astype(str)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "cat_df[categorical_cols] = cat_df[categorical_cols].apply(lambda col: le.fit_transform(col))\n",
        "\n",
        "#cat_df[categorical_cols].head(10)\n",
        "\n",
        "\n",
        "churn=cat_df['churn']\n",
        "cat_df=cat_df.drop(['churn'], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "num_df=num_df.fillna(conData)\n",
        "\n",
        "result_df = pd.concat([num_df, cat_df], axis=1)\n",
        "np.nan_to_num(result_df)\n",
        "\n",
        "result_df_op=result_df\n",
        "#result_df_op=result_df_op.drop(['churn'], axis=1)\n",
        "#result_df_op=np.nan_to_num(result_df_op)\n",
        "\n",
        "\n",
        "result_df_op=result_df\n",
        "\n",
        "X=result_df_op\n",
        "y=churn"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pArX1vH_-Phh"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "train=pd.concat([X_train, y_train], axis=1)\n",
        "test=pd.concat([X_test, y_test], axis=1)\n",
        "#train=pd.concat([X, y], axis=1)\n",
        "#test=pd.concat([X, y], axis=1)\n",
        "X_train=X\n",
        "X_test=X\n",
        "y_train=y\n",
        "y_test=y"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlzrGsdz-cGg"
      },
      "source": [
        "from google.colab import files\n",
        "import os, sys\n",
        "file_path = 'drive/My Drive/Colab Notebooks/private-data-generation/'\n",
        "#sys.path.append(file_path)\n",
        "sys.path.append(os.path.abspath(file_path))\n",
        "import sys\n",
        "sys.path.insert(1,'/content/drive/My Drive/Colab Notebooks/private-data-generation/')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_XQ2M7H-eM_"
      },
      "source": [
        "from models import dp_wgan, pate_gan, ron_gauss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3l37MCS-iBg"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingRegressor\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from sklearn import preprocessing\n",
        "from scipy.special import expit\n",
        "from models import dp_wgan, pate_gan, ron_gauss\n",
        "from models.Private_PGM import private_pgm\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import collections\n",
        "import os"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgpckIHs-eTf"
      },
      "source": [
        "class  Class_opt:\n",
        "    \"This is a person class\"\n",
        "    categorical = False\n",
        "    model='dp-wgan'\n",
        "    target_epsilon=80\n",
        "    target_delta=0.8\n",
        "    downstream_task=\"classification\"\n",
        "    target_variable='status'\n",
        "    batch_size=64\n",
        "    micro_batch_size=8\n",
        "    clamp_lower=0.01\n",
        "    clamp_upper=0.01\n",
        "    clip_coeff=0.1\n",
        "    sigma=2.0\n",
        "    num_epochs=50\n",
        "    enable_privacy=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "opt = Class_opt()\n",
        "opt.target_variable='churn'\n",
        "opt.categorical = True\n",
        "opt.model='dp-wgan'\n",
        "opt.target_epsilon=10\n",
        "opt.target_delta=0.1\n",
        "opt.batch_size=64\n",
        "opt.micro_batch_size=8\n",
        "opt.clamp_lower=0.01\n",
        "opt.clamp_upper=0.01\n",
        "opt.clip_coeff=0.1\n",
        "opt.sigma=0.8\n",
        "opt.num_epochs=100\n",
        "opt.enable_privacy=0\n",
        "\n",
        "opt.downstream_task=\"classification\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTiMgAjc-eWf"
      },
      "source": [
        "data_columns = [col for col in train.columns if col != opt.target_variable]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72DPHCJp-eZS",
        "outputId": "99368cba-e9d1-4f2e-a820-811890c56c49"
      },
      "source": [
        "class_ratios = train[opt.target_variable].sort_values().groupby(train[opt.target_variable]).size().values/train.shape[0]\n",
        "class_ratios"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.85714286, 0.14285714])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30XOtNBv-ebg"
      },
      "source": [
        "X_train = np.nan_to_num(train.drop([opt.target_variable], axis=1).values)\n",
        "y_train = np.nan_to_num(train[opt.target_variable].values)\n",
        "X_test = np.nan_to_num(test.drop([opt.target_variable], axis=1).values)\n",
        "y_test = np.nan_to_num(test[opt.target_variable].values)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-fsH8zI-ed9"
      },
      "source": [
        "#Normalized the data\n",
        "X_train = expit(X_train)\n",
        "X_test = expit(X_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0L13SnRt-ei9"
      },
      "source": [
        "input_dim = X_train.shape[1]\n",
        "z_dim = int(input_dim / 4 + 1) if input_dim % 4 == 0 else int(input_dim / 4)\n",
        "\n",
        "Hyperparams = collections.namedtuple('Hyperarams','batch_size micro_batch_size clamp_lower clamp_upper clip_coeff sigma class_ratios lr num_epochs')\n",
        "Hyperparams.__new__.__defaults__ = (None, None, None, None, None, None, None, None, None)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz2Y-lDN-elZ",
        "outputId": "531a0ec2-1e5d-4341-c9c6-2f12a9464c01"
      },
      "source": [
        "conditional = (opt.downstream_task == \"classification\")\n",
        "model = dp_wgan.DP_WGAN(input_dim, z_dim, opt.target_epsilon, opt.target_delta, conditional)\n",
        "model.train(X_train, y_train, Hyperparams(batch_size=opt.batch_size, micro_batch_size=opt.micro_batch_size,\n",
        "                                              clamp_lower=opt.clamp_lower, clamp_upper=opt.clamp_upper,\n",
        "                                              clip_coeff=opt.clip_coeff, sigma=opt.sigma, class_ratios=class_ratios, lr=\n",
        "                                              5e-5, num_epochs=opt.num_epochs), private=opt.enable_privacy)\n",
        "\n",
        "#torch.save(model, 'drive/My Drive/chk_p_GAN_MWOE_privacy_1_dataset5000_70-vs-30.pth')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1 Loss D real :  0.026657989678569482 Loss D fake :  0.011002818839330956 Loss G :  0.011118727358389239 Epsilon spent :  0\n",
            "Epoch : 2 Loss D real :  0.026728224471931916 Loss D fake :  0.011153026998677117 Loss G :  0.01093399902386024 Epsilon spent :  0\n",
            "Epoch : 3 Loss D real :  0.026661809167999637 Loss D fake :  0.010959531218511186 Loss G :  0.01109693054247186 Epsilon spent :  0\n",
            "Epoch : 4 Loss D real :  0.026806151369973694 Loss D fake :  0.010902755667437827 Loss G :  0.011081164859303046 Epsilon spent :  0\n",
            "Epoch : 5 Loss D real :  0.026672395599149176 Loss D fake :  0.010926754195643727 Loss G :  0.010929940736458954 Epsilon spent :  0\n",
            "Epoch : 6 Loss D real :  0.026798907800326174 Loss D fake :  0.011042944210176606 Loss G :  0.010979143632539774 Epsilon spent :  0\n",
            "Epoch : 7 Loss D real :  0.026689011597896405 Loss D fake :  0.011045257849786069 Loss G :  0.011096676848137883 Epsilon spent :  0\n",
            "Epoch : 8 Loss D real :  0.02668956299284982 Loss D fake :  0.010989345166126563 Loss G :  0.01096427488556639 Epsilon spent :  0\n",
            "Epoch : 9 Loss D real :  0.02674585588220015 Loss D fake :  0.011112016024401152 Loss G :  0.011006101814658878 Epsilon spent :  0\n",
            "Epoch : 10 Loss D real :  0.02673233570159179 Loss D fake :  0.011027417601126382 Loss G :  0.010858467274894925 Epsilon spent :  0\n",
            "Epoch : 11 Loss D real :  0.026622534455715347 Loss D fake :  0.010950206878086888 Loss G :  0.011030696330223386 Epsilon spent :  0\n",
            "Epoch : 12 Loss D real :  0.026666881166637433 Loss D fake :  0.01104431518738843 Loss G :  0.010894997854810295 Epsilon spent :  0\n",
            "Epoch : 13 Loss D real :  0.026631553239120805 Loss D fake :  0.010922025658155858 Loss G :  0.010897694418786687 Epsilon spent :  0\n",
            "Epoch : 14 Loss D real :  0.026640655245653257 Loss D fake :  0.010843429387516007 Loss G :  0.01106208948478511 Epsilon spent :  0\n",
            "Epoch : 15 Loss D real :  0.02675456436928304 Loss D fake :  0.010854336828453992 Loss G :  0.010979036109988315 Epsilon spent :  0\n",
            "Epoch : 16 Loss D real :  0.026641935019464155 Loss D fake :  0.010949395023872162 Loss G :  0.01091004415721291 Epsilon spent :  0\n",
            "Epoch : 17 Loss D real :  0.026734939756836214 Loss D fake :  0.010833997847073423 Loss G :  0.01080341091289386 Epsilon spent :  0\n",
            "Epoch : 18 Loss D real :  0.026627470240184668 Loss D fake :  0.010804924483235641 Loss G :  0.010905485085182326 Epsilon spent :  0\n",
            "Epoch : 19 Loss D real :  0.026741691538283343 Loss D fake :  0.010943037204123896 Loss G :  0.010794611661940894 Epsilon spent :  0\n",
            "Epoch : 20 Loss D real :  0.02677932744005414 Loss D fake :  0.010903333863290444 Loss G :  0.010842264220967849 Epsilon spent :  0\n",
            "Epoch : 21 Loss D real :  0.026721681525028407 Loss D fake :  0.01100187809112202 Loss G :  0.010898219534785224 Epsilon spent :  0\n",
            "Epoch : 22 Loss D real :  0.02670934532253182 Loss D fake :  0.010868629773171597 Loss G :  0.010844370313093373 Epsilon spent :  0\n",
            "Epoch : 23 Loss D real :  0.026722428175283874 Loss D fake :  0.010867327435384834 Loss G :  0.010783114529412188 Epsilon spent :  0\n",
            "Epoch : 24 Loss D real :  0.026716552075893053 Loss D fake :  0.010774508460536035 Loss G :  0.010701158408859244 Epsilon spent :  0\n",
            "Epoch : 25 Loss D real :  0.026783141299215458 Loss D fake :  0.010650389924152726 Loss G :  0.010703847812337793 Epsilon spent :  0\n",
            "Epoch : 26 Loss D real :  0.026780926433041505 Loss D fake :  0.010809367293898777 Loss G :  0.010764604397581319 Epsilon spent :  0\n",
            "Epoch : 27 Loss D real :  0.026683610441277525 Loss D fake :  0.01063980096145873 Loss G :  0.010703138279256827 Epsilon spent :  0\n",
            "Epoch : 28 Loss D real :  0.026730338211465997 Loss D fake :  0.01071703566852416 Loss G :  0.010714402713739014 Epsilon spent :  0\n",
            "Epoch : 29 Loss D real :  0.02669021175333249 Loss D fake :  0.010695775769115776 Loss G :  0.010612109585399446 Epsilon spent :  0\n",
            "Epoch : 30 Loss D real :  0.026666167886879942 Loss D fake :  0.010629233761914172 Loss G :  0.010566812218589482 Epsilon spent :  0\n",
            "Epoch : 31 Loss D real :  0.026725436049145464 Loss D fake :  0.01058407649809612 Loss G :  0.010708047197791414 Epsilon spent :  0\n",
            "Epoch : 32 Loss D real :  0.026696060938091768 Loss D fake :  0.01041942420390599 Loss G :  0.010560245883193327 Epsilon spent :  0\n",
            "Epoch : 33 Loss D real :  0.026686756143903277 Loss D fake :  0.010411272623373945 Loss G :  0.010385621881932757 Epsilon spent :  0\n",
            "Epoch : 34 Loss D real :  0.02673337137926289 Loss D fake :  0.010525436889162895 Loss G :  0.010538013430771846 Epsilon spent :  0\n",
            "Epoch : 35 Loss D real :  0.026720831019892862 Loss D fake :  0.010486793528825315 Loss G :  0.010414365474878734 Epsilon spent :  0\n",
            "Epoch : 36 Loss D real :  0.02672447473227507 Loss D fake :  0.010382725282673646 Loss G :  0.010537111210605413 Epsilon spent :  0\n",
            "Epoch : 37 Loss D real :  0.026609177880893384 Loss D fake :  0.010422538705642331 Loss G :  0.010512875059285495 Epsilon spent :  0\n",
            "Epoch : 38 Loss D real :  0.02664328940174009 Loss D fake :  0.010379420019729416 Loss G :  0.010376354256564455 Epsilon spent :  0\n",
            "Epoch : 39 Loss D real :  0.02658525114629765 Loss D fake :  0.010349163180420598 Loss G :  0.010429192426638874 Epsilon spent :  0\n",
            "Epoch : 40 Loss D real :  0.026595104365753283 Loss D fake :  0.010343078153901248 Loss G :  0.010477572046366845 Epsilon spent :  0\n",
            "Epoch : 41 Loss D real :  0.026692001128050855 Loss D fake :  0.01040793209544839 Loss G :  0.010334231999372988 Epsilon spent :  0\n",
            "Epoch : 42 Loss D real :  0.026747804263043868 Loss D fake :  0.010203026695445629 Loss G :  0.010367175729028223 Epsilon spent :  0\n",
            "Epoch : 43 Loss D real :  0.02665003321686269 Loss D fake :  0.01025270565721944 Loss G :  0.01032748969775572 Epsilon spent :  0\n",
            "Epoch : 44 Loss D real :  0.026775976427111457 Loss D fake :  0.010355286328051935 Loss G :  0.010239392790292597 Epsilon spent :  0\n",
            "Epoch : 45 Loss D real :  0.026703373445131542 Loss D fake :  0.01029498138356846 Loss G :  0.010242620967245276 Epsilon spent :  0\n",
            "Epoch : 46 Loss D real :  0.02669464080368977 Loss D fake :  0.01026450238210291 Loss G :  0.010306616084928102 Epsilon spent :  0\n",
            "Epoch : 47 Loss D real :  0.026707190085142742 Loss D fake :  0.010283573416289644 Loss G :  0.01026423050926346 Epsilon spent :  0\n",
            "Epoch : 48 Loss D real :  0.026714939392965452 Loss D fake :  0.010225366195852778 Loss G :  0.010276737364720824 Epsilon spent :  0\n",
            "Epoch : 49 Loss D real :  0.02678560000552471 Loss D fake :  0.010203258186707951 Loss G :  0.010252697894059436 Epsilon spent :  0\n",
            "Epoch : 50 Loss D real :  0.026751060448483046 Loss D fake :  0.010182009020862203 Loss G :  0.010282005980608444 Epsilon spent :  0\n",
            "Epoch : 51 Loss D real :  0.026754820347015984 Loss D fake :  0.010182321603273427 Loss G :  0.01015505348155081 Epsilon spent :  0\n",
            "Epoch : 52 Loss D real :  0.026729368958510958 Loss D fake :  0.010134669290049815 Loss G :  0.010181999454114712 Epsilon spent :  0\n",
            "Epoch : 53 Loss D real :  0.026693894877274773 Loss D fake :  0.010196102615922669 Loss G :  0.010160273618462428 Epsilon spent :  0\n",
            "Epoch : 54 Loss D real :  0.026742634813527167 Loss D fake :  0.010174587548112296 Loss G :  0.01020176336972771 Epsilon spent :  0\n",
            "Epoch : 55 Loss D real :  0.026601669802354656 Loss D fake :  0.01014596252248387 Loss G :  0.01013248746258909 Epsilon spent :  0\n",
            "Epoch : 56 Loss D real :  0.02655608926680473 Loss D fake :  0.010187433881542326 Loss G :  0.01015824910573103 Epsilon spent :  0\n",
            "Epoch : 57 Loss D real :  0.02666176583323204 Loss D fake :  0.010096839895235007 Loss G :  0.010158739503977388 Epsilon spent :  0\n",
            "Epoch : 58 Loss D real :  0.026579052349596264 Loss D fake :  0.010155670195544801 Loss G :  0.010116466542739367 Epsilon spent :  0\n",
            "Epoch : 59 Loss D real :  0.026696198405298584 Loss D fake :  0.010125967538334484 Loss G :  0.01014258976826703 Epsilon spent :  0\n",
            "Epoch : 60 Loss D real :  0.026574997032761335 Loss D fake :  0.010103773634166643 Loss G :  0.010106572877673697 Epsilon spent :  0\n",
            "Epoch : 61 Loss D real :  0.026873495246087464 Loss D fake :  0.01010264212111607 Loss G :  0.01011237740753491 Epsilon spent :  0\n",
            "Epoch : 62 Loss D real :  0.02669093365826222 Loss D fake :  0.010118326303843534 Loss G :  0.010111984115202966 Epsilon spent :  0\n",
            "Epoch : 63 Loss D real :  0.02672615617574141 Loss D fake :  0.010105723781750746 Loss G :  0.010057530716158218 Epsilon spent :  0\n",
            "Epoch : 64 Loss D real :  0.026644226878505917 Loss D fake :  0.010126744619745836 Loss G :  0.010064933472591608 Epsilon spent :  0\n",
            "Epoch : 65 Loss D real :  0.026637817384260843 Loss D fake :  0.010109950142926857 Loss G :  0.010079873949668479 Epsilon spent :  0\n",
            "Epoch : 66 Loss D real :  0.02675057402154899 Loss D fake :  0.010060683598570718 Loss G :  0.010082609855416197 Epsilon spent :  0\n",
            "Epoch : 67 Loss D real :  0.026791298845528753 Loss D fake :  0.010055973419186032 Loss G :  0.010093289640996296 Epsilon spent :  0\n",
            "Epoch : 68 Loss D real :  0.026558012888173128 Loss D fake :  0.010048275162124804 Loss G :  0.010076779972523493 Epsilon spent :  0\n",
            "Epoch : 69 Loss D real :  0.026745444443395702 Loss D fake :  0.010081648942506658 Loss G :  0.01005403209221959 Epsilon spent :  0\n",
            "Epoch : 70 Loss D real :  0.026715762717185797 Loss D fake :  0.010096331630689894 Loss G :  0.01007063966679235 Epsilon spent :  0\n",
            "Epoch : 71 Loss D real :  0.026756880046639443 Loss D fake :  0.010047991183878106 Loss G :  0.010091945915581324 Epsilon spent :  0\n",
            "Epoch : 72 Loss D real :  0.02652528979097007 Loss D fake :  0.010072191632010959 Loss G :  0.010051941829501388 Epsilon spent :  0\n",
            "Epoch : 73 Loss D real :  0.026798628795868584 Loss D fake :  0.010056738125598428 Loss G :  0.010041816476573498 Epsilon spent :  0\n",
            "Epoch : 74 Loss D real :  0.026654599974305828 Loss D fake :  0.01006733151140371 Loss G :  0.010044676915155672 Epsilon spent :  0\n",
            "Epoch : 75 Loss D real :  0.026712118096052784 Loss D fake :  0.010039805245197899 Loss G :  0.010045021913092846 Epsilon spent :  0\n",
            "Epoch : 76 Loss D real :  0.026794607900191243 Loss D fake :  0.010026405661000062 Loss G :  0.010016255503429577 Epsilon spent :  0\n",
            "Epoch : 77 Loss D real :  0.02659607944624572 Loss D fake :  0.010013166609324164 Loss G :  0.010018572704222293 Epsilon spent :  0\n",
            "Epoch : 78 Loss D real :  0.026587635834379387 Loss D fake :  0.010045671305874936 Loss G :  0.010048814082535827 Epsilon spent :  0\n",
            "Epoch : 79 Loss D real :  0.02672910971238613 Loss D fake :  0.010034249819255606 Loss G :  0.0100223398139863 Epsilon spent :  0\n",
            "Epoch : 80 Loss D real :  0.026710592071444106 Loss D fake :  0.010044908407056592 Loss G :  0.010041717678552817 Epsilon spent :  0\n",
            "Epoch : 81 Loss D real :  0.026638540855132963 Loss D fake :  0.01005495739914279 Loss G :  0.010037379729066372 Epsilon spent :  0\n",
            "Epoch : 82 Loss D real :  0.02665760271039885 Loss D fake :  0.010042830655744158 Loss G :  0.010034252191897543 Epsilon spent :  0\n",
            "Epoch : 83 Loss D real :  0.026663145156421774 Loss D fake :  0.010034374740234565 Loss G :  0.010012434485777825 Epsilon spent :  0\n",
            "Epoch : 84 Loss D real :  0.026695205251310805 Loss D fake :  0.010015551561917004 Loss G :  0.0100126060987679 Epsilon spent :  0\n",
            "Epoch : 85 Loss D real :  0.026758892550062825 Loss D fake :  0.01002444189719072 Loss G :  0.010044995833662348 Epsilon spent :  0\n",
            "Epoch : 86 Loss D real :  0.02664945305217522 Loss D fake :  0.010026906978792468 Loss G :  0.010026982202433702 Epsilon spent :  0\n",
            "Epoch : 87 Loss D real :  0.026701371763059374 Loss D fake :  0.010008178164987955 Loss G :  0.010032365264701831 Epsilon spent :  0\n",
            "Epoch : 88 Loss D real :  0.0266422444307685 Loss D fake :  0.010016636014848798 Loss G :  0.010020084436489456 Epsilon spent :  0\n",
            "Epoch : 89 Loss D real :  0.026610244979331562 Loss D fake :  0.010016514645489 Loss G :  0.010014317702194792 Epsilon spent :  0\n",
            "Epoch : 90 Loss D real :  0.026667532757188847 Loss D fake :  0.010016705890535275 Loss G :  0.010013256179023235 Epsilon spent :  0\n",
            "Epoch : 91 Loss D real :  0.026683189280833536 Loss D fake :  0.010012258634015989 Loss G :  0.010009339592733913 Epsilon spent :  0\n",
            "Epoch : 92 Loss D real :  0.026612024703639225 Loss D fake :  0.01000761647242983 Loss G :  0.010011661940469731 Epsilon spent :  0\n",
            "Epoch : 93 Loss D real :  0.026720313339941026 Loss D fake :  0.01003071879077777 Loss G :  0.010017792069162795 Epsilon spent :  0\n",
            "Epoch : 94 Loss D real :  0.026672323308099665 Loss D fake :  0.010008307357552232 Loss G :  0.01002115142709183 Epsilon spent :  0\n",
            "Epoch : 95 Loss D real :  0.026622474980856854 Loss D fake :  0.010018137351655751 Loss G :  0.010024558815593467 Epsilon spent :  0\n",
            "Epoch : 96 Loss D real :  0.02676313771480879 Loss D fake :  0.010015916088782025 Loss G :  0.01001196505448829 Epsilon spent :  0\n",
            "Epoch : 97 Loss D real :  0.026707436605326818 Loss D fake :  0.010016367408403722 Loss G :  0.010024763652614233 Epsilon spent :  0\n",
            "Epoch : 98 Loss D real :  0.026831024416929163 Loss D fake :  0.010014141793801327 Loss G :  0.010014976260061939 Epsilon spent :  0\n",
            "Epoch : 99 Loss D real :  0.026593974616575276 Loss D fake :  0.010017175411540716 Loss G :  0.010007264220199616 Epsilon spent :  0\n",
            "Epoch : 100 Loss D real :  0.02674461330492195 Loss D fake :  0.010006852559283474 Loss G :  0.010007158977925947 Epsilon spent :  0\n",
            "Epoch : 101 Loss D real :  0.026774489356679608 Loss D fake :  0.010013255229518354 Loss G :  0.0100079128535195 Epsilon spent :  0\n",
            "Epoch : 102 Loss D real :  0.026658723287118623 Loss D fake :  0.010008747602503813 Loss G :  0.010015878797650531 Epsilon spent :  0\n",
            "Epoch : 103 Loss D real :  0.026741249338768935 Loss D fake :  0.010002580084039491 Loss G :  0.010006583205854824 Epsilon spent :  0\n",
            "Epoch : 104 Loss D real :  0.026700390943464897 Loss D fake :  0.010000262589364279 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 105 Loss D real :  0.02667069467845349 Loss D fake :  0.010023927554829731 Loss G :  0.010005900502152663 Epsilon spent :  0\n",
            "Epoch : 106 Loss D real :  0.026634659977175696 Loss D fake :  0.0100005909105856 Loss G :  0.01000827053583476 Epsilon spent :  0\n",
            "Epoch : 107 Loss D real :  0.0266975289075707 Loss D fake :  0.01000537533048269 Loss G :  0.01001419686752519 Epsilon spent :  0\n",
            "Epoch : 108 Loss D real :  0.026703229994651034 Loss D fake :  0.010000168766361221 Loss G :  0.01000768351669089 Epsilon spent :  0\n",
            "Epoch : 109 Loss D real :  0.026636621665239488 Loss D fake :  0.010014245302866345 Loss G :  0.01000191938861653 Epsilon spent :  0\n",
            "Epoch : 110 Loss D real :  0.026639086552646636 Loss D fake :  0.010027213722249375 Loss G :  0.01000625783504186 Epsilon spent :  0\n",
            "Epoch : 111 Loss D real :  0.02675351586880853 Loss D fake :  0.010002701688515404 Loss G :  0.010019960638176185 Epsilon spent :  0\n",
            "Epoch : 112 Loss D real :  0.026685069239858108 Loss D fake :  0.01000304591279677 Loss G :  0.010004745668751463 Epsilon spent :  0\n",
            "Epoch : 113 Loss D real :  0.026700488227513437 Loss D fake :  0.010002341950264679 Loss G :  0.010003409137188888 Epsilon spent :  0\n",
            "Epoch : 114 Loss D real :  0.026827128743584356 Loss D fake :  0.010001870676761433 Loss G :  0.01000709495984799 Epsilon spent :  0\n",
            "Epoch : 115 Loss D real :  0.026726214286672823 Loss D fake :  0.01000958702548961 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 116 Loss D real :  0.026699261238148794 Loss D fake :  0.01 Loss G :  0.010004817384292687 Epsilon spent :  0\n",
            "Epoch : 117 Loss D real :  0.026671231319788356 Loss D fake :  0.010013106584549404 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 118 Loss D real :  0.02668921559731766 Loss D fake :  0.010006382952615571 Loss G :  0.010000377507327646 Epsilon spent :  0\n",
            "Epoch : 119 Loss D real :  0.026626210383805537 Loss D fake :  0.010003618013742964 Loss G :  0.010007285347091254 Epsilon spent :  0\n",
            "Epoch : 120 Loss D real :  0.026863177922354372 Loss D fake :  0.01 Loss G :  0.010013115043274736 Epsilon spent :  0\n",
            "Epoch : 121 Loss D real :  0.026704926857311094 Loss D fake :  0.010000542420177066 Loss G :  0.010002574239743375 Epsilon spent :  0\n",
            "Epoch : 122 Loss D real :  0.026740120146893274 Loss D fake :  0.010001229109855032 Loss G :  0.010003130568450133 Epsilon spent :  0\n",
            "Epoch : 123 Loss D real :  0.02680997795405484 Loss D fake :  0.010002781555892074 Loss G :  0.01000732610982621 Epsilon spent :  0\n",
            "Epoch : 124 Loss D real :  0.026703675217153673 Loss D fake :  0.01 Loss G :  0.010001265563033634 Epsilon spent :  0\n",
            "Epoch : 125 Loss D real :  0.026623562318461233 Loss D fake :  0.01 Loss G :  0.01000383134490132 Epsilon spent :  0\n",
            "Epoch : 126 Loss D real :  0.026877320301045816 Loss D fake :  0.010003623438727214 Loss G :  0.010000418766656433 Epsilon spent :  0\n",
            "Epoch : 127 Loss D real :  0.026603092267220897 Loss D fake :  0.010014810230809499 Loss G :  0.010003424032978372 Epsilon spent :  0\n",
            "Epoch : 128 Loss D real :  0.02674019253963078 Loss D fake :  0.01 Loss G :  0.010001942357659534 Epsilon spent :  0\n",
            "Epoch : 129 Loss D real :  0.026618337187424655 Loss D fake :  0.010004737734693105 Loss G :  0.010003628874158503 Epsilon spent :  0\n",
            "Epoch : 130 Loss D real :  0.026818346995361172 Loss D fake :  0.010000880242629778 Loss G :  0.01000329521704258 Epsilon spent :  0\n",
            "Epoch : 131 Loss D real :  0.026602876739612712 Loss D fake :  0.01000170601528208 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 132 Loss D real :  0.026567515408157227 Loss D fake :  0.010006181228397937 Loss G :  0.010005450677969919 Epsilon spent :  0\n",
            "Epoch : 133 Loss D real :  0.02666750064052855 Loss D fake :  0.01 Loss G :  0.010004001898712443 Epsilon spent :  0\n",
            "Epoch : 134 Loss D real :  0.026564448791167893 Loss D fake :  0.010003067728396854 Loss G :  0.010000282917038885 Epsilon spent :  0\n",
            "Epoch : 135 Loss D real :  0.02660823451879034 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 136 Loss D real :  0.0266611946990297 Loss D fake :  0.010001383496424838 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 137 Loss D real :  0.026705187172040158 Loss D fake :  0.010002487508544603 Loss G :  0.010000513151476481 Epsilon spent :  0\n",
            "Epoch : 138 Loss D real :  0.026697126220410382 Loss D fake :  0.010000280453463684 Loss G :  0.010001008762880112 Epsilon spent :  0\n",
            "Epoch : 139 Loss D real :  0.026715705949120722 Loss D fake :  0.010000691607590526 Loss G :  0.010003034557386038 Epsilon spent :  0\n",
            "Epoch : 140 Loss D real :  0.026796114267877837 Loss D fake :  0.01 Loss G :  0.010000783346335522 Epsilon spent :  0\n",
            "Epoch : 141 Loss D real :  0.02684799715449988 Loss D fake :  0.01 Loss G :  0.010000245532251234 Epsilon spent :  0\n",
            "Epoch : 142 Loss D real :  0.026772299847187608 Loss D fake :  0.010002110388586807 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 143 Loss D real :  0.026677828671148693 Loss D fake :  0.010001761805599635 Loss G :  0.010000358985258143 Epsilon spent :  0\n",
            "Epoch : 144 Loss D real :  0.02669081853522889 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 145 Loss D real :  0.026630834747022103 Loss D fake :  0.01000301770863894 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 146 Loss D real :  0.026806627968666508 Loss D fake :  0.010003401712607628 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 147 Loss D real :  0.026631562204451065 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 148 Loss D real :  0.02681004637285427 Loss D fake :  0.01 Loss G :  0.010001544148143148 Epsilon spent :  0\n",
            "Epoch : 149 Loss D real :  0.02680878791762948 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 150 Loss D real :  0.026666741357476553 Loss D fake :  0.010000432571391275 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 151 Loss D real :  0.026616011191405827 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 152 Loss D real :  0.026777502570736446 Loss D fake :  0.01000163006827192 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 153 Loss D real :  0.02669468503231742 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 154 Loss D real :  0.026729217170724115 Loss D fake :  0.01 Loss G :  0.01000475375078063 Epsilon spent :  0\n",
            "Epoch : 155 Loss D real :  0.026666775691573337 Loss D fake :  0.010000411996476465 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 156 Loss D real :  0.026672722722907223 Loss D fake :  0.010000722369350675 Loss G :  0.010002385189205945 Epsilon spent :  0\n",
            "Epoch : 157 Loss D real :  0.026703645302160513 Loss D fake :  0.010001044895560505 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 158 Loss D real :  0.02655046375855303 Loss D fake :  0.010000097554766278 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 159 Loss D real :  0.026598332774925824 Loss D fake :  0.01 Loss G :  0.010002104918765516 Epsilon spent :  0\n",
            "Epoch : 160 Loss D real :  0.026688546735004766 Loss D fake :  0.01 Loss G :  0.010000353809908952 Epsilon spent :  0\n",
            "Epoch : 161 Loss D real :  0.0267215867381164 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 162 Loss D real :  0.026627435504655118 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 163 Loss D real :  0.02662567281941931 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 164 Loss D real :  0.02679186040974489 Loss D fake :  0.010000482431580061 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 165 Loss D real :  0.026675252159098148 Loss D fake :  0.010001069163897917 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 166 Loss D real :  0.026656135720091786 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 167 Loss D real :  0.02676276758278587 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 168 Loss D real :  0.026706362776620196 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 169 Loss D real :  0.02673646867772963 Loss D fake :  0.010000118166281567 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 170 Loss D real :  0.02669244045384537 Loss D fake :  0.010001466793514813 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 171 Loss D real :  0.02686345118598444 Loss D fake :  0.01 Loss G :  0.010002113442711229 Epsilon spent :  0\n",
            "Epoch : 172 Loss D real :  0.02659930171718834 Loss D fake :  0.01 Loss G :  0.010002181511301885 Epsilon spent :  0\n",
            "Epoch : 173 Loss D real :  0.02671999643653272 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 174 Loss D real :  0.026697609342509643 Loss D fake :  0.01 Loss G :  0.010001168520603156 Epsilon spent :  0\n",
            "Epoch : 175 Loss D real :  0.02660308624972337 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 176 Loss D real :  0.026589901863000722 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 177 Loss D real :  0.02669384680569198 Loss D fake :  0.010001045920530919 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 178 Loss D real :  0.026754050808774243 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 179 Loss D real :  0.026593573994953535 Loss D fake :  0.01000167017064206 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 180 Loss D real :  0.02681416824221905 Loss D fake :  0.01 Loss G :  0.010002028436833028 Epsilon spent :  0\n",
            "Epoch : 181 Loss D real :  0.02663650837501208 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 182 Loss D real :  0.026750850798733457 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 183 Loss D real :  0.026603205571245615 Loss D fake :  0.01 Loss G :  0.010001163315564752 Epsilon spent :  0\n",
            "Epoch : 184 Loss D real :  0.02672409253253318 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 185 Loss D real :  0.026781389918207756 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 186 Loss D real :  0.02658419661067444 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 187 Loss D real :  0.026658499023256517 Loss D fake :  0.01 Loss G :  0.01000021653407672 Epsilon spent :  0\n",
            "Epoch : 188 Loss D real :  0.02667454997414723 Loss D fake :  0.01 Loss G :  0.01000112906155744 Epsilon spent :  0\n",
            "Epoch : 189 Loss D real :  0.026772832809196453 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 190 Loss D real :  0.026645779707076912 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 191 Loss D real :  0.026773247251485534 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 192 Loss D real :  0.026648435233827778 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 193 Loss D real :  0.02666324471271687 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 194 Loss D real :  0.02676544288458762 Loss D fake :  0.01 Loss G :  0.01000039448858243 Epsilon spent :  0\n",
            "Epoch : 195 Loss D real :  0.026582025311129943 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 196 Loss D real :  0.026750710282757408 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 197 Loss D real :  0.026588992208678962 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 198 Loss D real :  0.026671718639487453 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 199 Loss D real :  0.026782855407206485 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 200 Loss D real :  0.02674942372460145 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  0\n",
            "Epoch : 201 Loss D real :  0.026819833866867267 Loss D fake :  0.01 Loss G :  0.01 Epsilon spent :  inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgmVMwIs-eni"
      },
      "source": [
        "if opt.model == 'imle' or opt.model == 'dp-wgan' or opt.model == 'pate-gan':\n",
        "    syn_data = model.generate(X_train.shape[0], class_ratios)\n",
        "    X_syn, y_syn = syn_data[:, :-1], syn_data[:, -1]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVHDjtpZ-eqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e10deb-2425-4019-b14d-cd7dfcf596d6"
      },
      "source": [
        "X_syn_df = pd.DataFrame(data=X_syn, columns=data_columns)\n",
        "y_syn_df = pd.DataFrame(data=y_syn, columns=[opt.target_variable])\n",
        "\n",
        "syn_df = pd.concat([X_syn_df, y_syn_df], axis=1)\n",
        "syn_df.to_csv(\"drive/My Drive/synthetic_data_GAN_1_70per_training_dataset5000_Feb_2024_set0.csv\")\n",
        "test.to_csv(\"drive/My Drive/Original_data_GAN_1_30per_testing_dataseat5000_Feb_2024.csv\")\n",
        "print(\"Saved synthetic data at : \", \"drive/My Drive/synthetic_data_GAN_mWOE_privacy_1_70percent_training_dataset5000.csv\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved synthetic data at :  drive/My Drive/synthetic_data_GAN_mWOE_privacy_1_70percent_training_dataset5000.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class WOE_Encoder():\n",
        "    def __init__(self, cols=None, size=None):\n",
        "            self.cols = cols\n",
        "            self.min_samples=1\n",
        "            #self.bins=10000\n",
        "            self.bins=int(size/10)\n",
        "            self._mapping = {}\n",
        "\n",
        "    def WOE_fit(self, X, y):\n",
        "        for col in self.cols:\n",
        "            X[col]=X[col].fillna(-9999)\n",
        "            if (len(np.unique(X[col]))>100):\n",
        "                binned_x = pd.qcut(X[col], self.bins,  duplicates='drop')\n",
        "                d0 = pd.DataFrame({'x': binned_x, 'y':y})\n",
        "            else:\n",
        "                d0 = pd.DataFrame({'x': X[col], 'y': y})\n",
        "            #print (d0)\n",
        "            # Share of positive (resp. negative) labels for each category P(X=X_i | Y=1) (resp. P(X=X_i | Y=0))\n",
        "            #mapping = y.groupby(X[col]).agg(['sum', 'count']).rename({'sum': 'pos'}, axis=1)\n",
        "            mapping = y.groupby(d0[\"x\"]).agg(['sum', 'count']).rename({'sum': 'pos'}, axis=1)\n",
        "            mapping['neg'] = mapping['count'] - mapping['pos']\n",
        "            mapping[['pos', 'neg']] /= mapping[['pos', 'neg']].sum()\n",
        "            # For corner cases, defaulting to WOE = 0 (meaning no info). To avoid division by 0 we use default values.\n",
        "            undef = (mapping['count'] < self.min_samples) | (mapping['pos'] == 0) | (mapping['neg'] == 0)\n",
        "            mapping.loc[undef, ['pos', 'neg']] = -1\n",
        "            # Final step, log of ratio of probabily estimates\n",
        "            mapping['value'] = np.log((mapping['pos'] +0.0001)/ (mapping['neg']+0.0001))\n",
        "            self._mapping[col] = mapping\n",
        "\n",
        "\n",
        "        X_encoded = X.copy(deep=True)\n",
        "        for col, mapping in self._mapping.items():\n",
        "            X_encoded.loc[:, col] = X_encoded[col].fillna(-9999).map(mapping['value'])\n",
        "            X_encoded[col].fillna(0, inplace=True)\n",
        "\n",
        "        return X_encoded"
      ],
      "metadata": {
        "id": "cPAYcJoBkZ2M"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "syn_df=pd.read_csv('drive/My Drive/synthetic_data_GAN_1_70per_training_dataset5000_Feb_2024_set0.csv')\n",
        "y_syn_df=syn_df['churn']\n",
        "X_syn_df=syn_df.drop(['churn'], axis=1)\n",
        "Obj = WOE_Encoder(cols=X_syn_df.columns, size=X_syn_df.shape[0])\n",
        "X_encoded = Obj.WOE_fit(X_syn_df, y_syn_df)\n",
        "X_encoded.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "g0VHipf1kgti",
        "outputId": "75c9b07a-f781-46a8-fafb-a09428b9da11"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  account_length  area_code  number_vmail_messages  \\\n",
              "0   -0.415918        0.366349   0.891860               1.322689   \n",
              "1   -0.415918        0.000000   1.716180              -0.415918   \n",
              "2   -0.415918       -0.415918   0.366349               0.000000   \n",
              "3   -0.415918       -0.415918   0.000000               0.000000   \n",
              "4   -0.415918       -0.415918   0.000000              -0.415918   \n",
              "\n",
              "   total_day_minutes  total_day_calls  total_day_charge  total_eve_minutes  \\\n",
              "0           1.322689        -0.415918          1.322689           0.891860   \n",
              "1          -0.415918        -0.415918          2.105956           1.716180   \n",
              "2           0.000000         0.000000          0.366349           0.366349   \n",
              "3           0.000000        -0.415918          0.000000           0.891860   \n",
              "4          -0.415918         0.891860         -0.415918          -0.415918   \n",
              "\n",
              "   total_eve_calls  total_eve_charge  total_night_minutes  total_night_calls  \\\n",
              "0         0.366349         -0.415918             0.891860           0.891860   \n",
              "1         0.891860          0.366349            -0.415918           0.366349   \n",
              "2         0.000000          0.366349             0.366349           1.716180   \n",
              "3        -0.415918          0.366349            -0.415918           0.000000   \n",
              "4        -0.415918          0.891860            -0.415918           0.000000   \n",
              "\n",
              "   total_night_charge  total_intl_minutes  total_intl_calls  \\\n",
              "0           -0.415918            0.366349          0.366349   \n",
              "1           -0.415918            0.000000          0.366349   \n",
              "2            0.000000            0.000000          0.000000   \n",
              "3            0.000000            0.891860          0.366349   \n",
              "4            0.000000            1.322689          0.366349   \n",
              "\n",
              "   total_intl_charge  number_customer_service_calls     state  \\\n",
              "0           0.891860                      -0.415918  0.891860   \n",
              "1          -0.415918                      -0.415918  0.366349   \n",
              "2           0.000000                      -0.415918  0.000000   \n",
              "3           0.000000                       0.891860 -0.415918   \n",
              "4          -0.415918                       0.891860  0.366349   \n",
              "\n",
              "   international_plan  voice_mail_plan  \n",
              "0            3.705492         0.891860  \n",
              "1            0.891860         1.322689  \n",
              "2            0.366349         0.000000  \n",
              "3           -0.415918        -0.415918  \n",
              "4            0.891860         0.891860  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9e4fd15-8fc3-40c4-b531-4fbfd6989195\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>account_length</th>\n",
              "      <th>area_code</th>\n",
              "      <th>number_vmail_messages</th>\n",
              "      <th>total_day_minutes</th>\n",
              "      <th>total_day_calls</th>\n",
              "      <th>total_day_charge</th>\n",
              "      <th>total_eve_minutes</th>\n",
              "      <th>total_eve_calls</th>\n",
              "      <th>total_eve_charge</th>\n",
              "      <th>total_night_minutes</th>\n",
              "      <th>total_night_calls</th>\n",
              "      <th>total_night_charge</th>\n",
              "      <th>total_intl_minutes</th>\n",
              "      <th>total_intl_calls</th>\n",
              "      <th>total_intl_charge</th>\n",
              "      <th>number_customer_service_calls</th>\n",
              "      <th>state</th>\n",
              "      <th>international_plan</th>\n",
              "      <th>voice_mail_plan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>1.322689</td>\n",
              "      <td>1.322689</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>1.322689</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>3.705492</td>\n",
              "      <td>0.891860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.716180</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>2.105956</td>\n",
              "      <td>1.716180</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>1.322689</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>1.716180</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.322689</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>-0.415918</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>0.366349</td>\n",
              "      <td>0.891860</td>\n",
              "      <td>0.891860</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9e4fd15-8fc3-40c4-b531-4fbfd6989195')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b9e4fd15-8fc3-40c4-b531-4fbfd6989195 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b9e4fd15-8fc3-40c4-b531-4fbfd6989195');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2ffefb28-5c1e-4723-b1b8-2a1a10ba2888\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ffefb28-5c1e-4723-b1b8-2a1a10ba2888')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2ffefb28-5c1e-4723-b1b8-2a1a10ba2888 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "#Create a Gaussian Classifier\n",
        "classifier = GaussianNB(priors=None, var_smoothing=6.579332246575682e-09)\n",
        "\n",
        "classifier.fit(X_encoded,y_syn)\n",
        "\n",
        "\n",
        "cv_method = RepeatedKFold(n_splits=10,\n",
        "                          n_repeats=3,\n",
        "                          random_state=999)\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred  = cross_val_predict(estimator = classifier, X = X_encoded, y = y_syn_df, cv = 5)\n",
        "tn, fp, fn, tp  = confusion_matrix(y_syn_df, y_pred).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "pod=tp/(tp+fn)\n",
        "\n",
        "print('pod: ',pod)\n",
        "pof=fp/(fp+tn)\n",
        "print ('pof: ',pof)\n",
        "auc_val=(1+pod-pof)/2\n",
        "print ('AUC: ',auc_val)\n",
        "\n",
        "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
        "print ('accuracy: ',accuracy)"
      ],
      "metadata": {
        "id": "scfedaPIk5S5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b02291-ea5e-49bb-9cef-290ce08bfe04"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2796 192 40 472\n",
            "pod:  0.921875\n",
            "pof:  0.0642570281124498\n",
            "AUC:  0.9288089859437751\n",
            "accuracy:  0.9337142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "org_test_df=pd.read_csv('drive/My Drive/Original_data_GAN_1_30per_testing_dataseat5000_Feb_2024.csv')\n",
        "y_test=org_test_df['churn']\n",
        "X_test=org_test_df.drop(['churn'], axis=1)\n",
        "Obj_test = WOE_Encoder(cols=X_test.columns, size=X_test.shape[0])\n",
        "X_encoded_test = Obj_test.WOE_fit(X_test, y_test)\n",
        "X_encoded_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "qM2CrRSmlHrc",
        "outputId": "4ddf444a-9cb9-49d7-e658-6f4e8ecc10f3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  account_length  area_code  number_vmail_messages  \\\n",
              "0   -0.358999        0.039822   0.031013               0.200916   \n",
              "1    1.410377       -0.111723  -0.018455               0.200916   \n",
              "2   -0.358999       -0.358999   0.004923               0.000000   \n",
              "3    0.000000        0.900476  -0.018455               0.200916   \n",
              "4   -0.358999        0.323957  -0.018455               0.200916   \n",
              "\n",
              "   total_day_minutes  total_day_calls  total_day_charge  total_eve_minutes  \\\n",
              "0           1.810602        -0.605655          1.410377           0.973277   \n",
              "1          -0.462942         0.221536          0.000000           0.000000   \n",
              "2          -0.358999        -0.647981          0.000000          -0.358999   \n",
              "3          -0.242985         0.517807          0.323957          -0.242985   \n",
              "4          -0.358999        -0.013731          0.000000          -0.242985   \n",
              "\n",
              "   total_eve_calls  total_eve_charge  total_night_minutes  total_night_calls  \\\n",
              "0         0.272236          0.973277            -0.358999          -0.928147   \n",
              "1        -0.643134          0.000000             0.000000          -0.864143   \n",
              "2         0.409120         -0.358999            -0.358999           0.172797   \n",
              "3         0.683962          0.000000             0.000000           0.441866   \n",
              "4         0.000000         -0.557091             0.000000          -0.561457   \n",
              "\n",
              "   total_night_charge  total_intl_minutes  total_intl_calls  \\\n",
              "0            0.000000            0.441866          0.242130   \n",
              "1           -0.557091            0.326591          0.242130   \n",
              "2            0.622058            0.289240         -0.284555   \n",
              "3            0.323957            0.000000          0.242130   \n",
              "4           -0.358999            0.000000         -0.284555   \n",
              "\n",
              "   total_intl_charge  number_customer_service_calls     state  \\\n",
              "0           0.441866                      -0.276281 -0.203610   \n",
              "1           0.326591                      -0.249514 -0.077157   \n",
              "2           0.289240                      -0.249514  0.480250   \n",
              "3           0.000000                      -0.249514 -0.214692   \n",
              "4           0.000000                      -0.249514 -0.688589   \n",
              "\n",
              "   international_plan  voice_mail_plan  \n",
              "0           -0.308443         0.201986  \n",
              "1           -0.308443         0.201986  \n",
              "2           -0.308443        -0.872765  \n",
              "3           -0.308443         0.201986  \n",
              "4           -0.308443         0.201986  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63ec127e-5e61-4560-bc99-98eb65d8b762\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>account_length</th>\n",
              "      <th>area_code</th>\n",
              "      <th>number_vmail_messages</th>\n",
              "      <th>total_day_minutes</th>\n",
              "      <th>total_day_calls</th>\n",
              "      <th>total_day_charge</th>\n",
              "      <th>total_eve_minutes</th>\n",
              "      <th>total_eve_calls</th>\n",
              "      <th>total_eve_charge</th>\n",
              "      <th>total_night_minutes</th>\n",
              "      <th>total_night_calls</th>\n",
              "      <th>total_night_charge</th>\n",
              "      <th>total_intl_minutes</th>\n",
              "      <th>total_intl_calls</th>\n",
              "      <th>total_intl_charge</th>\n",
              "      <th>number_customer_service_calls</th>\n",
              "      <th>state</th>\n",
              "      <th>international_plan</th>\n",
              "      <th>voice_mail_plan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.358999</td>\n",
              "      <td>0.039822</td>\n",
              "      <td>0.031013</td>\n",
              "      <td>0.200916</td>\n",
              "      <td>1.810602</td>\n",
              "      <td>-0.605655</td>\n",
              "      <td>1.410377</td>\n",
              "      <td>0.973277</td>\n",
              "      <td>0.272236</td>\n",
              "      <td>0.973277</td>\n",
              "      <td>-0.358999</td>\n",
              "      <td>-0.928147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.441866</td>\n",
              "      <td>0.242130</td>\n",
              "      <td>0.441866</td>\n",
              "      <td>-0.276281</td>\n",
              "      <td>-0.203610</td>\n",
              "      <td>-0.308443</td>\n",
              "      <td>0.201986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.410377</td>\n",
              "      <td>-0.111723</td>\n",
              "      <td>-0.018455</td>\n",
              "      <td>0.200916</td>\n",
              "      <td>-0.462942</td>\n",
              "      <td>0.221536</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.643134</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.864143</td>\n",
              "      <td>-0.557091</td>\n",
              "      <td>0.326591</td>\n",
              "      <td>0.242130</td>\n",
              "      <td>0.326591</td>\n",
              "      <td>-0.249514</td>\n",
              "      <td>-0.077157</td>\n",
              "      <td>-0.308443</td>\n",
              "      <td>0.201986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.358999</td>\n",
              "      <td>-0.358999</td>\n",
              "      <td>0.004923</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.358999</td>\n",
              "      <td>-0.647981</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.358999</td>\n",
              "      <td>0.409120</td>\n",
              "      <td>-0.358999</td>\n",
              "      <td>-0.358999</td>\n",
              "      <td>0.172797</td>\n",
              "      <td>0.622058</td>\n",
              "      <td>0.289240</td>\n",
              "      <td>-0.284555</td>\n",
              "      <td>0.289240</td>\n",
              "      <td>-0.249514</td>\n",
              "      <td>0.480250</td>\n",
              "      <td>-0.308443</td>\n",
              "      <td>-0.872765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.900476</td>\n",
              "      <td>-0.018455</td>\n",
              "      <td>0.200916</td>\n",
              "      <td>-0.242985</td>\n",
              "      <td>0.517807</td>\n",
              "      <td>0.323957</td>\n",
              "      <td>-0.242985</td>\n",
              "      <td>0.683962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.441866</td>\n",
              "      <td>0.323957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.242130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.249514</td>\n",
              "      <td>-0.214692</td>\n",
              "      <td>-0.308443</td>\n",
              "      <td>0.201986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.358999</td>\n",
              "      <td>0.323957</td>\n",
              "      <td>-0.018455</td>\n",
              "      <td>0.200916</td>\n",
              "      <td>-0.358999</td>\n",
              "      <td>-0.013731</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.242985</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.557091</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.561457</td>\n",
              "      <td>-0.358999</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.284555</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.249514</td>\n",
              "      <td>-0.688589</td>\n",
              "      <td>-0.308443</td>\n",
              "      <td>0.201986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63ec127e-5e61-4560-bc99-98eb65d8b762')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63ec127e-5e61-4560-bc99-98eb65d8b762 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63ec127e-5e61-4560-bc99-98eb65d8b762');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a122dd6e-b2c5-4c0e-b5dd-371da2469253\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a122dd6e-b2c5-4c0e-b5dd-371da2469253')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a122dd6e-b2c5-4c0e-b5dd-371da2469253 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import Gaussian Naive Bayes model\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "#Create a Gaussian Classifier\n",
        "classifier = GaussianNB(priors=None, var_smoothing=6.579332246575682e-09)\n",
        "\n",
        "classifier.fit(X_encoded,y_syn_df)\n",
        "\n",
        "\n",
        "cv_method = RepeatedKFold(n_splits=10, n_repeats=3, random_state=999)\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#y_pred  = cross_val_predict(estimator = classifier, X = X_encoded, y = y_syn, cv = 5)\n",
        "y_pred = classifier.predict(X_encoded_test)\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "pod=tp/(tp+fn)\n",
        "\n",
        "print('pod: ',pod)\n",
        "pof=fp/(fp+tn)\n",
        "print ('pof: ',pof)\n",
        "auc_val=(1+pod-pof)/2\n",
        "print ('AUC: ',auc_val)\n",
        "\n",
        "recall = tp/(tp+fn)\n",
        "print ('recall: ',recall)\n",
        "precision=tp/(tp+fp)\n",
        "print ('precision: ',precision)\n",
        "\n",
        "F1_score=(2*precision*recall)/(precision+recall)\n",
        "print ('F1-Score: ',F1_score)\n",
        "\n",
        "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
        "print ('accuracy: ',accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYSleMWhlM-c",
        "outputId": "ff023eac-d8e1-439d-848c-88769e026918"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1281 12 104 103\n",
            "pod:  0.4975845410628019\n",
            "pof:  0.009280742459396751\n",
            "AUC:  0.7441518993017026\n",
            "recall:  0.4975845410628019\n",
            "precision:  0.8956521739130435\n",
            "F1-Score:  0.639751552795031\n",
            "accuracy:  0.9226666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "classifier = LogisticRegression(C=5, class_weight=None, dual=False, fit_intercept=True,\n",
        "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
        "          n_jobs=None, penalty='l1', random_state=None, solver='liblinear',\n",
        "          tol=0.0001, verbose=0, warm_start=False)\n",
        "classifier.fit(X_encoded,y_syn_df)\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#y_pred  = cross_val_predict(estimator = classifier, X = X_encoded, y = y_syn, cv = 10)\n",
        "y_pred = classifier.predict(X_encoded_test)\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "pod=tp/(tp+fn)\n",
        "\n",
        "print('pod: ',pod)\n",
        "pof=fp/(fp+tn)\n",
        "print ('pof: ',pof)\n",
        "auc_val=(1+pod-pof)/2\n",
        "print ('AUC: ',auc_val)\n",
        "\n",
        "\n",
        "recall = tp/(tp+fn)\n",
        "print ('recall: ',recall)\n",
        "precision=tp/(tp+fp)\n",
        "print ('precision: ',precision)\n",
        "\n",
        "F1_score=(2*precision*recall)/(precision+recall)\n",
        "print ('F1-Score: ',F1_score)\n",
        "\n",
        "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
        "print ('accuracy: ',accuracy)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSHysmTioCI2",
        "outputId": "7315e0a9-6efe-4e8b-93af-fa554f0743d0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1292 1 166 41\n",
            "pod:  0.19806763285024154\n",
            "pof:  0.0007733952049497294\n",
            "AUC:  0.5986471188226459\n",
            "recall:  0.19806763285024154\n",
            "precision:  0.9761904761904762\n",
            "F1-Score:  0.32931726907630515\n",
            "accuracy:  0.8886666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier =RandomForestClassifier(bootstrap= True, max_depth= 80, max_features= 3, min_samples_leaf= 3, min_samples_split= 12, n_estimators= 1000)\n",
        "classifier.fit(X_encoded,y_syn_df)\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
        "y_pred = classifier.predict(X_encoded_test)\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "pod=tp/(tp+fn)\n",
        "\n",
        "print('pod: ',pod)\n",
        "pof=fp/(fp+tn)\n",
        "print ('pof: ',pof)\n",
        "auc_val=(1+pod-pof)/2\n",
        "print ('AUC: ',auc_val)\n",
        "\n",
        "recall = tp/(tp+fn)\n",
        "print ('recall: ',recall)\n",
        "precision=tp/(tp+fp)\n",
        "print ('precision: ',precision)\n",
        "\n",
        "F1_score=(2*precision*recall)/(precision+recall)\n",
        "print ('F1-Score: ',F1_score)\n",
        "\n",
        "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
        "print ('accuracy: ',accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUzpo1DFqHb1",
        "outputId": "2745821f-f376-47ab-be2c-ceecf3c879ed"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1292 1 185 22\n",
            "pod:  0.10628019323671498\n",
            "pof:  0.0007733952049497294\n",
            "AUC:  0.5527533990158826\n",
            "recall:  0.10628019323671498\n",
            "precision:  0.9565217391304348\n",
            "F1-Score:  0.19130434782608693\n",
            "accuracy:  0.876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(metric='manhattan', weights='uniform', n_neighbors=19 )\n",
        "classifier.fit(X_encoded,y_syn_df)\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
        "y_pred = classifier.predict(X_encoded_test)\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "pod=tp/(tp+fn)\n",
        "\n",
        "print('pod: ',pod)\n",
        "pof=fp/(fp+tn)\n",
        "print ('pof: ',pof)\n",
        "auc_val=(1+pod-pof)/2\n",
        "print ('AUC: ',auc_val)\n",
        "\n",
        "recall = tp/(tp+fn)\n",
        "print ('recall: ',recall)\n",
        "precision=tp/(tp+fp)\n",
        "print ('precision: ',precision)\n",
        "\n",
        "F1_score=(2*precision*recall)/(precision+recall)\n",
        "print ('F1-Score: ',F1_score)\n",
        "\n",
        "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
        "print ('accuracy: ',accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz9F7A76rVus",
        "outputId": "69fa0079-7c77-413c-fbb1-cf033f258ac1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1293 0 200 7\n",
            "pod:  0.033816425120772944\n",
            "pof:  0.0\n",
            "AUC:  0.5169082125603864\n",
            "recall:  0.033816425120772944\n",
            "precision:  1.0\n",
            "F1-Score:  0.06542056074766354\n",
            "accuracy:  0.8666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#classifier = DecisionTreeClassifier(criterion='entropy', splitter='best')\n",
        "classifier = DecisionTreeClassifier()\n",
        "classifier.fit(X_encoded,y_syn_df)\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#y_pred  = cross_val_predict(estimator = classifier, X = x_train_chi, y = y_train, cv = 10)\n",
        "y_pred = classifier.predict(X_encoded_test)\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "pod=tp/(tp+fn)\n",
        "\n",
        "print('pod: ',pod)\n",
        "pof=fp/(fp+tn)\n",
        "print ('pof: ',pof)\n",
        "auc_val=(1+pod-pof)/2\n",
        "print ('AUC: ',auc_val)\n",
        "\n",
        "\n",
        "recall = tp/(tp+fn)\n",
        "print ('recall: ',recall)\n",
        "precision=tp/(tp+fp)\n",
        "print ('precision: ',precision)\n",
        "\n",
        "F1_score=(2*precision*recall)/(precision+recall)\n",
        "print ('F1-Score: ',F1_score)\n",
        "\n",
        "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
        "print ('accuracy: ',accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aXKt4zNyIhP",
        "outputId": "40cf09eb-423a-4e4b-fbf3-88a0f2c833a7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1261 32 132 75\n",
            "pod:  0.36231884057971014\n",
            "pof:  0.02474864655839134\n",
            "AUC:  0.6687850970106595\n",
            "recall:  0.36231884057971014\n",
            "precision:  0.7009345794392523\n",
            "F1-Score:  0.4777070063694267\n",
            "accuracy:  0.8906666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Gradient Boosting\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "#classifier = GradientBoostingClassifier(max_features=None, max_depth=3, criterion='friedman_mse')\n",
        "classifier = GradientBoostingClassifier()\n",
        "classifier.fit(X_encoded,y_syn_df)\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = classifier.predict(X_encoded_test)\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "pod=tp/(tp+fn)\n",
        "\n",
        "print('pod: ',pod)\n",
        "pof=fp/(fp+tn)\n",
        "print ('pof: ',pof)\n",
        "auc_val=(1+pod-pof)/2\n",
        "print ('AUC: ',auc_val)\n",
        "\n",
        "\n",
        "recall = tp/(tp+fn)\n",
        "print ('recall: ',recall)\n",
        "precision=tp/(tp+fp)\n",
        "print ('precision: ',precision)\n",
        "\n",
        "F1_score=(2*precision*recall)/(precision+recall)\n",
        "print ('F1-Score: ',F1_score)\n",
        "\n",
        "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
        "print ('accuracy: ',accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pc3EhNOr0SI",
        "outputId": "c472e865-8a56-4e48-bd94-301e5ca8696a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1291 2 173 34\n",
            "pod:  0.1642512077294686\n",
            "pof:  0.0015467904098994587\n",
            "AUC:  0.5813522086597847\n",
            "recall:  0.1642512077294686\n",
            "precision:  0.9444444444444444\n",
            "F1-Score:  0.27983539094650206\n",
            "accuracy:  0.8833333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#XGBClassifier\n",
        "from xgboost import XGBClassifier\n",
        "classifier =  XGBClassifier(random_state=0)\n",
        "\n",
        "classifier.fit(X_encoded,y_syn_df)\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#y_pred  = cross_val_predict(estimator = classifier, X = X, y = y, cv = 10)\n",
        "y_pred = classifier.predict(X_encoded_test)\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test, y_pred).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "pod=tp/(tp+fn)\n",
        "\n",
        "print('pod: ',pod)\n",
        "pof=fp/(fp+tn)\n",
        "print ('pof: ',pof)\n",
        "auc_val=(1+pod-pof)/2\n",
        "print ('AUC: ',auc_val)\n",
        "\n",
        "\n",
        "recall = tp/(tp+fn)\n",
        "print ('recall: ',recall)\n",
        "precision=tp/(tp+fp)\n",
        "print ('precision: ',precision)\n",
        "\n",
        "F1_score=(2*precision*recall)/(precision+recall)\n",
        "print ('F1-Score: ',F1_score)\n",
        "\n",
        "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
        "print ('accuracy: ',accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcS-p-a6zjv8",
        "outputId": "d49a9c30-c82a-4d16-88ec-f056d6aa6a83"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1293 0 194 13\n",
            "pod:  0.06280193236714976\n",
            "pof:  0.0\n",
            "AUC:  0.5314009661835749\n",
            "recall:  0.06280193236714976\n",
            "precision:  1.0\n",
            "F1-Score:  0.11818181818181818\n",
            "accuracy:  0.8706666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FNN\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#create model\n",
        "model = Sequential()\n",
        "#get number of columns in training data\n",
        "n_cols = X_encoded_test.shape[1]\n",
        "model.add(Dense(10, activation='relu', input_shape=(n_cols,)))\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#compile model using mse as a measure of model performance\n",
        "#model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "from keras.callbacks import EarlyStopping\n",
        "#set early stopping monitor so the model stops training when it won't improve anymore\n",
        "early_stopping_monitor = EarlyStopping(patience=3)\n",
        "#train model\n",
        "\n",
        "model.fit(X_encoded, y_syn_df, validation_split=0.2, epochs=30, callbacks=[early_stopping_monitor])\n",
        "y_pred = model.predict(X_encoded_test)\n",
        "y22_pred=y_pred.round()\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test, y22_pred).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "pod=tp/(tp+fn)\n",
        "\n",
        "print('pod: ',pod)\n",
        "pof=fp/(fp+tn)\n",
        "print ('pof: ',pof)\n",
        "auc_val=(1+pod-pof)/2\n",
        "print ('AUC: ',auc_val)\n",
        "\n",
        "\n",
        "recall = tp/(tp+fn)\n",
        "print ('recall: ',recall)\n",
        "precision=tp/(tp+fp)\n",
        "print ('precision: ',precision)\n",
        "\n",
        "F1_score=(2*precision*recall)/(precision+recall)\n",
        "print ('F1-Score: ',F1_score)\n",
        "\n",
        "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
        "print ('accuracy: ',accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThIySQdwfHSJ",
        "outputId": "79b66776-2b62-484a-faea-0c686c44e873"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "88/88 [==============================] - 5s 12ms/step - loss: 0.3678 - accuracy: 0.8679 - val_loss: 0.2502 - val_accuracy: 0.8971\n",
            "Epoch 2/30\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.2269 - accuracy: 0.9050 - val_loss: 0.1889 - val_accuracy: 0.9229\n",
            "Epoch 3/30\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.9293 - val_loss: 0.1731 - val_accuracy: 0.9243\n",
            "Epoch 4/30\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1574 - accuracy: 0.9393 - val_loss: 0.1545 - val_accuracy: 0.9414\n",
            "Epoch 5/30\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.1504 - accuracy: 0.9393 - val_loss: 0.1526 - val_accuracy: 0.9457\n",
            "Epoch 6/30\n",
            "88/88 [==============================] - 0s 5ms/step - loss: 0.1364 - accuracy: 0.9446 - val_loss: 0.1545 - val_accuracy: 0.9471\n",
            "Epoch 7/30\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1319 - accuracy: 0.9468 - val_loss: 0.1474 - val_accuracy: 0.9443\n",
            "Epoch 8/30\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1258 - accuracy: 0.9507 - val_loss: 0.1452 - val_accuracy: 0.9457\n",
            "Epoch 9/30\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1199 - accuracy: 0.9507 - val_loss: 0.1509 - val_accuracy: 0.9400\n",
            "Epoch 10/30\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1138 - accuracy: 0.9511 - val_loss: 0.1450 - val_accuracy: 0.9386\n",
            "Epoch 11/30\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9554 - val_loss: 0.1479 - val_accuracy: 0.9471\n",
            "Epoch 12/30\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1129 - accuracy: 0.9546 - val_loss: 0.1519 - val_accuracy: 0.9486\n",
            "Epoch 13/30\n",
            "88/88 [==============================] - 0s 4ms/step - loss: 0.1052 - accuracy: 0.9575 - val_loss: 0.1698 - val_accuracy: 0.9429\n",
            "47/47 [==============================] - 0s 2ms/step\n",
            "1289 4 145 62\n",
            "pod:  0.2995169082125604\n",
            "pof:  0.0030935808197989174\n",
            "AUC:  0.6482116636963807\n",
            "recall:  0.2995169082125604\n",
            "precision:  0.9393939393939394\n",
            "F1-Score:  0.4542124542124542\n",
            "accuracy:  0.9006666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_G9KVrg-exy"
      },
      "source": [],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YDT5In3-e1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea82c5a4-8192-46a7-bfaf-7ff433cfa122"
      },
      "source": [
        "#RNN\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout, LSTM, GRU\n",
        "from keras.layers import Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "#from tensorflow.keras.optimizers.legacy import Adam\n",
        "\n",
        "import numpy as np\n",
        "max_features = 10000 # number of words to consider as features\n",
        "#create model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#model.compile(optimizer='rmsprop',loss='binary_crossentropy', metrics=['acc'])\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "history = model.fit(X_encoded, y_syn_df, epochs=5, batch_size=128, validation_split=0.2)\n",
        "y2_pred = model.predict(X_encoded_test)\n",
        "y22_pred=y2_pred.round()\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn, fp, fn, tp  = confusion_matrix(y_test, y22_pred).ravel()\n",
        "print(tn, fp, fn, tp)\n",
        "pod=tp/(tp+fn)\n",
        "\n",
        "print('pod: ',pod)\n",
        "pof=fp/(fp+tn)\n",
        "print ('pof: ',pof)\n",
        "auc_val=(1+pod-pof)/2\n",
        "print ('AUC: ',auc_val)\n",
        "\n",
        "\n",
        "recall = tp/(tp+fn)\n",
        "print ('recall: ',recall)\n",
        "precision=tp/(tp+fp)\n",
        "print ('precision: ',precision)\n",
        "\n",
        "F1_score=(2*precision*recall)/(precision+recall)\n",
        "print ('F1-Score: ',F1_score)\n",
        "\n",
        "accuracy=(tp+tn)/(tp+fn+fp+tn)\n",
        "print ('accuracy: ',accuracy)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          320000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                8320      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 328353 (1.25 MB)\n",
            "Trainable params: 328353 (1.25 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n",
            "22/22 [==============================] - 4s 29ms/step - loss: 0.6043 - accuracy: 0.8500 - val_loss: 0.4465 - val_accuracy: 0.8529\n",
            "Epoch 2/5\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8539 - val_loss: 0.3727 - val_accuracy: 0.8529\n",
            "Epoch 3/5\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.3401 - accuracy: 0.8539 - val_loss: 0.3139 - val_accuracy: 0.8543\n",
            "Epoch 4/5\n",
            "22/22 [==============================] - 0s 6ms/step - loss: 0.2695 - accuracy: 0.8654 - val_loss: 0.2221 - val_accuracy: 0.8871\n",
            "Epoch 5/5\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.2282 - accuracy: 0.9029 - val_loss: 0.2051 - val_accuracy: 0.9143\n",
            "47/47 [==============================] - 0s 2ms/step\n",
            "1292 1 173 34\n",
            "pod:  0.1642512077294686\n",
            "pof:  0.0007733952049497294\n",
            "AUC:  0.5817389062622594\n",
            "recall:  0.1642512077294686\n",
            "precision:  0.9714285714285714\n",
            "F1-Score:  0.2809917355371901\n",
            "accuracy:  0.884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQ-APCXJ-e23"
      },
      "source": [],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnWV3KbP-e5p"
      },
      "source": [],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS-PQ06L-e89"
      },
      "source": [],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngzlHAS4-e_b"
      },
      "source": [],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFEZ96NO-fBf"
      },
      "source": [],
      "execution_count": 44,
      "outputs": []
    }
  ]
}